{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Addition and Subtraction using RNNs",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYzeWBZUxoRE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from termcolor import colored"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Using Pytorch Version - {torch.__version__}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IqA2sNox5jw",
        "outputId": "2f90e26c-b40a-4df1-a8a5-eaff22fa7691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Pytorch Version - 1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_chars = '0123456789+-'\n",
        "num_features = len(all_chars)\n",
        "char_to_index = {c : i for i, c in enumerate(all_chars)}\n",
        "index_to_char = {i : c for i, c in enumerate(all_chars)}\n",
        "print(f'Number of features : {len(all_chars)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Z7wPxAyE77",
        "outputId": "2c74f197-382b-4967-cb93-62f5f6c293fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data():\n",
        "    first_num = np.random.randint(low=0,high=100)\n",
        "    second_num = np.random.randint(low=0,high=100)\n",
        "    add = np.squeeze(np.random.randint(low=0, high=100)) > 50.\n",
        "    if add:\n",
        "        example = str(first_num) + '+' + str(second_num)\n",
        "        label = str(first_num+second_num)\n",
        "    else:\n",
        "        example = str(first_num) + '-' + str(second_num)\n",
        "        label = str(first_num-second_num)\n",
        "    return example, label\n",
        "\n",
        "generate_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u06NAxJ8y15a",
        "outputId": "b1bc84d6-6e8b-49ad-84f8-756b5e30a3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('74+10', '84')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_time_steps = 5\n",
        "x = np.zeros((max_time_steps, num_features))\n",
        "y = np.zeros((max_time_steps, num_features))\n",
        "print(x)\n",
        "print()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgoFcLKf2x57",
        "outputId": "8ef0fbb1-72ad-49ea-c00b-3e147d722c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(example, label):\n",
        "    \n",
        "    x = np.zeros((max_time_steps, num_features))\n",
        "    y = np.zeros((max_time_steps, num_features))\n",
        "    \n",
        "    diff_x = max_time_steps - len(example)\n",
        "    diff_y = max_time_steps - len(label)\n",
        "    \n",
        "    for i, c in enumerate(example):\n",
        "        x[diff_x+i, char_to_index[c]] = 1\n",
        "    for i in range(diff_x):\n",
        "        x[i, char_to_index['0']] = 1\n",
        "    for i, c in enumerate(label):\n",
        "        y[diff_y+i, char_to_index[c]] = 1\n",
        "    for i in range(diff_y):\n",
        "        y[i, char_to_index['0']] = 1\n",
        "        \n",
        "    return x, y"
      ],
      "metadata": {
        "id": "Km9Kn4h097vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e, l = generate_data()\n",
        "print(f'Text Example and Label : {e, l}')\n",
        "x, y = encode(e, l)\n",
        "print(f'Vectorized Example and Label : {x, y}')\n",
        "print()\n",
        "print(f'Shapes of Vectorized Example : {x.shape, y.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqIT5l-lFFUw",
        "outputId": "35395153-a6fe-471e-95c1-06e1d70b805b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Example and Label : ('25+66', '91')\n",
            "Vectorized Example and Label : (array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))\n",
            "\n",
            "Shapes of Vectorized Example : ((5, 12), (5, 12))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(example):\n",
        "  res = [index_to_char[np.argmax(vec)] for i, vec in enumerate(example)]\n",
        "  return ''.join(res)\n",
        "\n",
        "def strip_zeros(example):\n",
        "    encountered_non_zero = False\n",
        "    output = ''\n",
        "    for c in example:\n",
        "        if not encountered_non_zero and c == '0':\n",
        "            continue\n",
        "        if c == '+' or c == '-':\n",
        "            encountered_non_zero = False\n",
        "        else:\n",
        "            encountered_non_zero = True\n",
        "        output += c\n",
        "    return output"
      ],
      "metadata": {
        "id": "rfvT9ivrFazB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(strip_zeros(decode(y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50pzy-GtIXpv",
        "outputId": "027f3462-caa2-4f86-b85f-6660f93aeccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx_m6XCvIZb1",
        "outputId": "b1d503b4-9d77-4a74-eef7-add9479c7925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(num_examples=200000):\n",
        "\n",
        "    x_train = np.zeros((num_examples, max_time_steps, num_features))\n",
        "    y_train = np.zeros((num_examples, max_time_steps, num_features))\n",
        "\n",
        "    for i in range(num_examples):\n",
        "        e, l = generate_data()\n",
        "        x, y = encode(e, l)\n",
        "        x_train[i] = x\n",
        "        y_train[i] = y\n",
        "    \n",
        "    return x_train, y_train\n",
        "\n",
        "x_train, y_train = create_dataset(200000)\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjx1fzT-KaEm",
        "outputId": "8dda442a-2f9b-4d4f-ce56-2e4b899c29e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200000, 5, 12) (200000, 5, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xFZYo8XKkTB",
        "outputId": "005b2bc0-0775-465b-89d9-3a699a3df93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200000, 5, 12) (200000, 5, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYZotJ31MMGx",
        "outputId": "b340bc39-1c2b-435b-c729-25e411c027a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(x_train[0]))"
      ],
      "metadata": {
        "id": "Za9nPVWnMRJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "047c7598-4e82-4735-9026-416202a21385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46-79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(y_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3tQYfD75omh",
        "outputId": "187ddace-88d3-4d97-fc28-1045e43191c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00-33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.from_numpy(x_train)\n",
        "y_train = torch.from_numpy(y_train)\n",
        "x_train = torch.tensor(x_train, dtype = torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype = torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytKdNHEn5rzH",
        "outputId": "dd298ef9-cabe-4d6b-fc28-f44d37679349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using Device : {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4RFYb0U56eI",
        "outputId": "bbfa0251-ec33-4866-d7cd-beebfde18a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_dim,n_layers):\n",
        "    super(SimpleRNN, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        "    self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first = True)\n",
        "    self.fc1 = nn.Linear(hidden_dim,hidden_dim * 2)\n",
        "    self.fc2 = nn.Linear(hidden_dim * 2, output_size)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size = x.size(0)\n",
        "    hidden = self.init_hidden(batch_size)\n",
        "    hidden = hidden.cuda()\n",
        "    out, hidden = self.rnn(x, hidden)\n",
        "    #out = out.contiguous().view(-1, self.hidden_dim)\n",
        "    out = self.fc1(out)\n",
        "    out = self.fc2(self.relu(out))\n",
        "\n",
        "    return out, hidden\n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "    return hidden"
      ],
      "metadata": {
        "id": "zQOy0gWj6F4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNN(input_size = num_features, output_size = num_features , hidden_dim = 12, n_layers = 10)\n",
        "model.cuda()\n",
        "\n",
        "n_epochs = 1000\n",
        "lr = 0.01\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "uwMWW0AF7aYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  optimizer.zero_grad()\n",
        "  x_train = x_train.cuda()\n",
        "  output, hidden = model(x_train)\n",
        "  #print(output.shape,y_train.shape)\n",
        "  loss = criterion(output, y_train.cuda())\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "    print(\"Loss: {:.4f}\".format(loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpwE_h8s8Mul",
        "outputId": "4e8fffbd-9be6-47cb-f41a-04766bed37df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/1000............. Loss: 0.5646\n",
            "Epoch: 20/1000............. Loss: 0.4723\n",
            "Epoch: 30/1000............. Loss: 0.4440\n",
            "Epoch: 40/1000............. Loss: 0.4381\n",
            "Epoch: 50/1000............. Loss: 0.4360\n",
            "Epoch: 60/1000............. Loss: 0.4347\n",
            "Epoch: 70/1000............. Loss: 0.4335\n",
            "Epoch: 80/1000............. Loss: 0.4317\n",
            "Epoch: 90/1000............. Loss: 0.4340\n",
            "Epoch: 100/1000............. Loss: 0.4319\n",
            "Epoch: 110/1000............. Loss: 0.4300\n",
            "Epoch: 120/1000............. Loss: 0.4278\n",
            "Epoch: 130/1000............. Loss: 0.4283\n",
            "Epoch: 140/1000............. Loss: 0.4252\n",
            "Epoch: 150/1000............. Loss: 0.4234\n",
            "Epoch: 160/1000............. Loss: 0.4207\n",
            "Epoch: 170/1000............. Loss: 0.4204\n",
            "Epoch: 180/1000............. Loss: 0.4193\n",
            "Epoch: 190/1000............. Loss: 0.4177\n",
            "Epoch: 200/1000............. Loss: 0.4167\n",
            "Epoch: 210/1000............. Loss: 0.4164\n",
            "Epoch: 220/1000............. Loss: 0.4132\n",
            "Epoch: 230/1000............. Loss: 0.4162\n",
            "Epoch: 240/1000............. Loss: 0.4113\n",
            "Epoch: 250/1000............. Loss: 0.4078\n",
            "Epoch: 260/1000............. Loss: 0.4128\n",
            "Epoch: 270/1000............. Loss: 0.4029\n",
            "Epoch: 280/1000............. Loss: 0.3982\n",
            "Epoch: 290/1000............. Loss: 0.3941\n",
            "Epoch: 300/1000............. Loss: 0.4236\n",
            "Epoch: 310/1000............. Loss: 0.4075\n",
            "Epoch: 320/1000............. Loss: 0.3988\n",
            "Epoch: 330/1000............. Loss: 0.3928\n",
            "Epoch: 340/1000............. Loss: 0.3890\n",
            "Epoch: 350/1000............. Loss: 0.3890\n",
            "Epoch: 360/1000............. Loss: 0.3860\n",
            "Epoch: 370/1000............. Loss: 0.3826\n",
            "Epoch: 380/1000............. Loss: 0.3830\n",
            "Epoch: 390/1000............. Loss: 0.3831\n",
            "Epoch: 400/1000............. Loss: 0.3840\n",
            "Epoch: 410/1000............. Loss: 0.3760\n",
            "Epoch: 420/1000............. Loss: 0.3730\n",
            "Epoch: 430/1000............. Loss: 0.3706\n",
            "Epoch: 440/1000............. Loss: 0.3902\n",
            "Epoch: 450/1000............. Loss: 0.3782\n",
            "Epoch: 460/1000............. Loss: 0.3715\n",
            "Epoch: 470/1000............. Loss: 0.3683\n",
            "Epoch: 480/1000............. Loss: 0.3663\n",
            "Epoch: 490/1000............. Loss: 0.3660\n",
            "Epoch: 500/1000............. Loss: 0.3740\n",
            "Epoch: 510/1000............. Loss: 0.3657\n",
            "Epoch: 520/1000............. Loss: 0.3639\n",
            "Epoch: 530/1000............. Loss: 0.3627\n",
            "Epoch: 540/1000............. Loss: 0.3638\n",
            "Epoch: 550/1000............. Loss: 0.3606\n",
            "Epoch: 560/1000............. Loss: 0.3659\n",
            "Epoch: 570/1000............. Loss: 0.3669\n",
            "Epoch: 580/1000............. Loss: 0.3648\n",
            "Epoch: 590/1000............. Loss: 0.3662\n",
            "Epoch: 600/1000............. Loss: 0.3601\n",
            "Epoch: 610/1000............. Loss: 0.3575\n",
            "Epoch: 620/1000............. Loss: 0.3564\n",
            "Epoch: 630/1000............. Loss: 0.3567\n",
            "Epoch: 640/1000............. Loss: 0.3643\n",
            "Epoch: 650/1000............. Loss: 0.4176\n",
            "Epoch: 660/1000............. Loss: 0.3935\n",
            "Epoch: 670/1000............. Loss: 0.3843\n",
            "Epoch: 680/1000............. Loss: 0.3785\n",
            "Epoch: 690/1000............. Loss: 0.3741\n",
            "Epoch: 700/1000............. Loss: 0.3704\n",
            "Epoch: 710/1000............. Loss: 0.3672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = create_dataset(num_examples=20)\n",
        "x_test = torch.from_numpy(x_test)\n",
        "y_test = torch.from_numpy(y_test)\n",
        "x_test = torch.tensor(x_test, dtype = torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype = torch.float32)\n",
        "preds, _ = model(x_test.cuda())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5rH311_F-AW",
        "outputId": "c0ca212c-21f5-4015-9227-ef6dafcfcd42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.cpu().numpy()\n",
        "x_test = x_test.cpu().numpy()"
      ],
      "metadata": {
        "id": "X6Jn7r6LINF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = preds.cpu();"
      ],
      "metadata": {
        "id": "QASBZy2ELNvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = preds.detach().numpy()"
      ],
      "metadata": {
        "id": "1NSHca2YLVzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_seq_acc = 0\n",
        "\n",
        "for i, pred in enumerate(preds):\n",
        "    pred_str = strip_zeros(decode(pred))\n",
        "    y_test_str = strip_zeros(decode(y_test[i]))\n",
        "    x_test_str = strip_zeros(decode(x_test[i]))\n",
        "    col = 'green' if pred_str == y_test_str else 'red'\n",
        "    full_seq_acc += 1/len(preds) * int(pred_str == y_test_str)\n",
        "    outstring = 'Input: {}, Out: {}, Pred: {}'.format(x_test_str, y_test_str, pred_str)\n",
        "    print(colored(outstring, col))\n",
        "print('\\nFull sequence accuracy: {:.3f} %'.format(100 * full_seq_acc))"
      ],
      "metadata": {
        "id": "pe45fMovGxen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, character):\n",
        "    # One-hot encoding our input to fit into the model\n",
        "    character = np.array([[char2int[c] for c in character]])\n",
        "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
        "    character = torch.from_numpy(character)\n",
        "    character.to(device)\n",
        "    \n",
        "    out, hidden = model(character)\n",
        "\n",
        "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
        "    # Taking the class with the highest probability score from the output\n",
        "    char_ind = torch.max(prob, dim=0)[1].item()\n",
        "\n",
        "    return int2char[char_ind], hidden"
      ],
      "metadata": {
        "id": "ONlDT8q98f0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model, out_len, start='hey'):\n",
        "    model.eval() # eval mode\n",
        "    start = start.lower()\n",
        "    # First off, run through the starting characters\n",
        "    chars = [ch for ch in start]\n",
        "    size = out_len - len(chars)\n",
        "    # Now pass in the previous characters and get a new one\n",
        "    for ii in range(size):\n",
        "        char, h = predict(model, chars)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "metadata": {
        "id": "6evHWUrUF26X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YL-jZP8ovSGi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}